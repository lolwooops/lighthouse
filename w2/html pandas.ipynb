{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we will download the source code to Python.\n",
    "url = 'https://www.worldcoinindex.com/'\n",
    "crypto_url = requests.get(url)\n",
    "crypto_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = crypto_url.text\n",
    "\n",
    "#Body now consists of full HTML source code of our webpage. \n",
    "#Now if the HTML source has a table which is marked by the HTML tag <table></table> \n",
    "#(this tag is used for defining a table in HTML) \n",
    "#Pandas uses read_html() to extract the table from the HTML document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_data = pd.read_html(body)\n",
    "print(type(crypto_data))\n",
    "print(len(crypto_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the above output, it is clear that there is a list with one element which is our table. Therefore\n",
    "\n",
    "crypto_data = crypto_data[0]\n",
    "crypto_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we want to extract information from HTML, which doesn't have a table, we need to use a different approach: Scraping. \n",
    "#Fortunately, Python has a great package for this called Beautiful Soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(soup.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(item) for item in list(soup.children)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = list(soup.children)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(html.children)\n",
    "body = list(html.children)[3]\n",
    "p = list(body.children)[1]\n",
    "p.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all at once\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup.find_all('p')\n",
    "soup.find_all('p')[0].get_text()\n",
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching by class/id\n",
    "\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup\n",
    "\n",
    "soup.find_all('p', class_='outer-text')\n",
    "\n",
    "soup.find_all(class_=\"outer-text\")\n",
    "\n",
    "soup.find_all(id=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#css selectors\n",
    "\n",
    "soup.select(\"div p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168\n",
    "\n",
    "\n",
    "#chrome devtools\n",
    "\n",
    "page = requests.get(\"http://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "seven_day = soup.find(id=\"seven-day-forecast\")\n",
    "forecast_items = seven_day.find_all(class_=\"tombstone-container\")\n",
    "tonight = forecast_items[0]\n",
    "print(tonight.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting info \n",
    "\n",
    "period = tonight.find(class_=\"period-name\").get_text()\n",
    "short_desc = tonight.find(class_=\"short-desc\").get_text()\n",
    "temp = tonight.find(class_=\"temp\").get_text()\n",
    "print(period)\n",
    "print(short_desc)\n",
    "print(temp)\n",
    "\n",
    "img = tonight.find(\"img\")\n",
    "desc = img['title']\n",
    "print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting all info\n",
    "\n",
    "period_tags = seven_day.select(\".tombstone-container .period-name\")\n",
    "periods = [pt.get_text() for pt in period_tags]\n",
    "periods\n",
    "\n",
    "#apply the same technique to get the other 3 fields:\n",
    "\n",
    "short_descs = [sd.get_text() for sd in seven_day.select(\".tombstone-container .short-desc\")]\n",
    "temps = [t.get_text() for t in seven_day.select(\".tombstone-container .temp\")]\n",
    "descs = [d[\"title\"] for d in seven_day.select(\".tombstone-container img\")]print(short_descs)print(temps)print(descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#into pandas\n",
    "\n",
    "import pandas as pd\n",
    "weather = pd.DataFrame({\n",
    "    \"period\": periods,\n",
    "    \"short_desc\": short_descs,\n",
    "    \"temp\": temps,\n",
    "    \"desc\":descs\n",
    "})\n",
    "weather\n",
    "\n",
    "#analysis\n",
    "\n",
    "temp_nums = weather[\"temp\"].str.extract(\"(?P<temp_num>d+)\", expand=False)\n",
    "weather[\"temp_num\"] = temp_nums.astype('int')\n",
    "temp_nums\n",
    "\n",
    "is_night = weather[\"temp\"].str.contains(\"Low\")\n",
    "weather[\"is_night\"] = is_night\n",
    "is_night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Libraries for Web Scraping\n",
    "\n",
    "# requests — this critical library is needed to actually get the data from the web server onto your machine, \n",
    "# and it contains some additional cool features like caching too.\n",
    "\n",
    "# Beautiful Soup 4 — This is the library we’ve used here, and it’s designed to make filtering data based on HTML \n",
    "# tags straightforward.\n",
    "\n",
    "# lmxl — An HTML and XML parser that’s fast (and now, integrated with Beautiful Soup, too!)\n",
    "\n",
    "# Selenium — A web driver tool that’s useful when you need to get data from a website that the requests library can’t access, \n",
    "# because it’s hidden behind things like login forms or mandatory mouse-clicks.\n",
    "\n",
    "# Scrapy — A full-on web scraping framework that might be overkill for one-off data analysis projects, but a good fit \n",
    "# when scraping’s required for production projects, pipelines, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
