{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Pipeline for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from numpy import sort\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use if you already have final_df.csv\n",
    "def get_data(filepath, file_name):\n",
    "    data = pd.read_csv(filepath+file_name)\n",
    "    return data\n",
    "\n",
    "# otherwise, use the following to scrape data\n",
    "def get_days():\n",
    "    days = []\n",
    "    mondays = []\n",
    "    first = pd.to_datetime(pd.Timestamp(year=2015, month=10, day=1))\n",
    "    for i in range(2015,2021): # get every monday since 2015\n",
    "        mondays += pd.date_range(start=str(i),\n",
    "                         end=str(i+1),\n",
    "                         freq='W-MON')\n",
    "    for monday in mondays:\n",
    "        d = monday.to_pydatetime()\n",
    "        if d >= first:\n",
    "            days.append(d)\n",
    "    return days\n",
    "\n",
    "\n",
    "months = {\n",
    "    1:'january',\n",
    "    2:'february',\n",
    "    3:'march',\n",
    "    4:'april',\n",
    "    5:'may',\n",
    "    6:'june',\n",
    "    7:'july',\n",
    "    8:'august',\n",
    "    9:'september',\n",
    "    10:'october',\n",
    "    11:'november',\n",
    "    12:'december'\n",
    "}\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "\n",
    "def rank_data():\n",
    "    days = get_days()\n",
    "    data = []\n",
    "    for i in range(len(days)):\n",
    "        day = days[i]\n",
    "        next_day = days[i + 1] - datetime.timedelta(days=1) if i < len(days) - 1 else date.today()\n",
    "        url = 'https://www.hltv.org/ranking/teams/' + \\\n",
    "            str(day.year) + '/' + \\\n",
    "            months[day.month] + '/' + str(day.day)\n",
    "        \n",
    "        res = requests.get(url,headers=headers)\n",
    "        \n",
    "#         if res.status_code != 200:\n",
    "#             continue\n",
    "#         else:\n",
    "        soup = BeautifulSoup(res.content, 'html.parser')\n",
    "        team_ranks = soup.findAll(\"div\",class_=\"ranked-team standard-box\")\n",
    "        pattern = re.compile('\\#(\\d+)')\n",
    "        teams = []\n",
    "        for team in team_ranks:\n",
    "            rank = pattern.match(team.find(\"span\",class_=\"position\").text).groups(1)[0]\n",
    "            name = team.find(\"span\",class_=\"name\").text\n",
    "            players = team.findAll(\"div\",class_=\"nick\")\n",
    "            playernames = [player.text for player in players]\n",
    "            date_range = pd.date_range(start=day,end=next_day)\n",
    "            for d in date_range:\n",
    "                teams.append([d, name, rank, playernames]) # have to do every day or else it only pulls 2019-12-30\n",
    "        \n",
    "        data+=teams\n",
    "        \n",
    "    df = pd.DataFrame(data=data, columns=['date','team','rank','player_names'])\n",
    "    \n",
    "    rank_df_csv = 'rank_df.csv'\n",
    "    rank_df = rank_data()\n",
    "    rank_df.to_csv(data_filepath+rank_df_csv, index=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "players = 'https://www.hltv.org/stats/players?startDate=all&matchType=Lan&rankingFilter=Top30'\n",
    "\n",
    "# returns a list of links for each player\n",
    "def get_links():\n",
    "    res = requests.get(players,headers=headers)\n",
    "    soup = BeautifulSoup(res.content,'html.parser')\n",
    "    cells = soup.find('table',class_='stats-table player-ratings-table').find('tbody').findAll('tr')\n",
    "    # table_body = players_table.find('tbody')\n",
    "    # player_cells = table.body.findAll('tr')\n",
    "\n",
    "    links = {}\n",
    "    for cell in cells:\n",
    "        link_tag = cell.find('td',class_='playerCol').find('a')\n",
    "        link = link_tag['href']\n",
    "        name = link_tag.text\n",
    "        links[name] = 'https://www.hltv.org' + link\n",
    "    return links\n",
    "\n",
    "def get_players(links):\n",
    "    data = []\n",
    "    # how score is formatted on this page (score = how many rounds team won vs lost)\n",
    "    score_re = re.compile(\"\\((\\d+)\\)\")\n",
    "    # how kill/death ratio is formatted on this page\n",
    "    kd_re = re.compile(\"(\\d+) - (\\d+)\")\n",
    "    \n",
    "    for player, link in links.items():\n",
    "        res = requests.get(link,headers=headers)\n",
    "        \n",
    "#         if res.status_code != 200:\n",
    "#             continue\n",
    "#         else:\n",
    "        soup = BeautifulSoup(res.content,'html.parser')\n",
    "        impact = soup.findAll('div',class_='summaryStatBreakdownRow')[1].find('div',class_='summaryStatBreakdownDataValue').text.strip()\n",
    "        \n",
    "        match_link = link.replace('/players','/players/matches')\n",
    "        res2 = requests.get(match_link, headers=headers)\n",
    "        \n",
    "#         if res2.status_code != 200:\n",
    "#             continue\n",
    "#         else:\n",
    "        soup2 = BeautifulSoup(res2.content,'html.parser')\n",
    "        rows = soup2.find('table').find('tbody').findAll('tr')\n",
    "            \n",
    "        for row in rows:\n",
    "            cells = row.findAll('td')\n",
    "            date = cells[0].find('div',class_='time').text.strip()\n",
    "            team = cells[1].findAll('span')[0].text.strip()\n",
    "            rounds_text = cells[1].findAll('span')[1].text.strip()\n",
    "            team_rounds = score_re.match(rounds_text).group(1)\n",
    "            opposing_team = cells[2].findAll('span')[0].text.strip()\n",
    "            opposing_team_rounds = score_re.match(cells[2].findAll('span')[1].text.strip()).group(1)\n",
    "            map_played = cells[3].text.strip()\n",
    "            kills = kd_re.match(cells[4].text.strip()).group(1)\n",
    "            deaths = kd_re.match(cells[4].text.strip()).group(2)\n",
    "            differential = cells[5].text.strip()\n",
    "            rating = cells[6].text.strip()\n",
    "            data.append([player, date, team, team_rounds, opposing_team,\n",
    "                         opposing_team_rounds, map_played, kills, deaths, differential, rating, impact])\n",
    "            \n",
    "        # data.append([impact])\n",
    "    columns = [\"player\", \"date\", \"team\", \"team_rounds\", \"opposing_team\",\n",
    "               \"opposing_team_rounds\", \"map\", \"kills\", \"deaths\", \"differential\", \"rating\", \"avg_impact\"]\n",
    "    df = pd.DataFrame(data=data, columns=columns)\n",
    "    \n",
    "    \n",
    "    match_df_csv = 'match_df.csv'\n",
    "    player_links = get_links()\n",
    "    match_df = get_players(player_links)\n",
    "    match_df.to_csv(data_filepath+match_df_csv, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def get_month():\n",
    "    rmonths = []\n",
    "    months = []\n",
    "    first = pd.to_datetime(pd.Timestamp(year=2015, month=10, day=1))\n",
    "    for i in range(2015,2021): # get every monday since 2015\n",
    "        months += pd.date_range(start=str(i),\n",
    "                         end=str(i+1),\n",
    "                         freq='MS')\n",
    "    for month in months:\n",
    "        d = month.to_pydatetime()\n",
    "        if d >= first:\n",
    "            rmonths.append(d)\n",
    "    return rmonths\n",
    "\n",
    "def team_data():\n",
    "    months = get_month()\n",
    "    data = []\n",
    "    for i in range(len(months)):\n",
    "        month = months[i]\n",
    "        nextmonth = months[i+1] if i < len(months) - 1 else months[i]\n",
    "        url = 'https://www.hltv.org/stats/teams/ftu?startDate={}&endDate={}&rankingFilter=Top30'.format(months[i].date(),nextmonth.date())\n",
    "        res = requests.get(url,headers=headers)\n",
    "        soup = BeautifulSoup(res.content,'html.parser')\n",
    "        stats = soup.find('table').find('tbody').findAll('tr')\n",
    "        team_ = []\n",
    "        for stat in stats:\n",
    "            cells = stat.findAll('td')\n",
    "            team = cells[0].find('a').text.strip()\n",
    "            p_rounds_won = cells[2].text.strip()\n",
    "            opening_duels = cells[3].text.strip()\n",
    "            multi_kills = cells[4].text.strip()\n",
    "            team_5v4 = cells[5].text.strip()\n",
    "            team_4v5 = cells[6].text.strip()\n",
    "            team_traded = cells[7].text.strip()\n",
    "            utility_adr = cells[8].text.strip()\n",
    "            utility_flash = cells[9].text.strip()\n",
    "            date_range = pd.date_range(start=month,end=nextmonth)\n",
    "            for m in date_range:\n",
    "                team_.append([m,team,p_rounds_won,opening_duels,multi_kills,\n",
    "                              team_5v4,team_4v5,team_traded,utility_adr,utility_flash])\n",
    "        \n",
    "        data+=team_\n",
    "    \n",
    "    columns = ['month','team','p_rounds_won','opening_duels','multi_kills',\n",
    "               'team_5v4','team_4v5','team_traded','utility_adr','utility_flash']\n",
    "    df = pd.DataFrame(data=data,columns=columns)\n",
    "    \n",
    "    team_df_csv = 'team_df.csv'\n",
    "    team_df = team_data()\n",
    "    team_df.to_csv(data_filepath+team_df_csv, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "# helper functions\n",
    "def get_rank(opponent, date):\n",
    "    ranks = ranking_df[ranking_df['date'] == date]\n",
    "    if len(ranks) == 0:\n",
    "        return -1\n",
    "    rows = ranks[ranks['team'] == opponent]\n",
    "    if(len(rows) == 0):\n",
    "        return -1\n",
    "    row = rows.iloc[[0]]\n",
    "    if len(row) == 0:\n",
    "        return -1\n",
    "    return row['rank'].iloc[0]\n",
    "\n",
    "# using https://www.desmos.com/calculator to model the weights\n",
    "def rank_weight(row):\n",
    "    if row['rank_differential'] < -2:\n",
    "        return 1.5\n",
    "    elif row['rank_differential'] > 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 1.75 - ((1 / (1 + math.exp(-0.5*row['rank_differential']))))\n",
    "\n",
    "def prep_scraped_data():\n",
    "#     rank_df_csv = 'rank_df.csv'\n",
    "#     ranking_df = pd.read_csv(data_filepath+rank_df_csv)\n",
    "#     match_df_csv = 'match_df.csv'\n",
    "#     match_df = pd.read_csv(data_filepath+match_df_csv)\n",
    "#     team_df_csv = 'team_df.csv'\n",
    "#     team_df = pd.read_csv(data_filepath+team_df_csv)\n",
    "    ranking_df = rank_data()\n",
    "    player_links = get_links()\n",
    "    match_df = get_players(player_links)\n",
    "    team_df = team_data()    \n",
    "    \n",
    "    ranking_df['date'] = pd.to_datetime(ranking_df.date)\n",
    "    match_df['date'] = pd.to_datetime(match_df.date)\n",
    "    team_df = team_df.rename(columns = {'month':'date'})\n",
    "    team_df['date'] = pd.to_datetime(team_df.date)\n",
    "    \n",
    "    df = copy.deepcopy(match_df)\n",
    "    \n",
    "    df = df.merge(team_df, on=['date','team'])\n",
    "    df['rating'] = df['rating'].replace(to_replace='\\*',value='',regex=True)\n",
    "    df['rating'] = pd.to_numeric(df['rating'])\n",
    "    df['win'] = df['team_rounds'] > df['opposing_team_rounds']\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    df['target'] = le.fit_transform(df['win'])\n",
    "    df = df.drop(columns = 'win')\n",
    "    \n",
    "    df['p_rounds_won'] = df['p_rounds_won'].replace(to_replace='\\%',value='',regex=True)\n",
    "    df['p_rounds_won'] = pd.to_numeric(df['p_rounds_won'])\n",
    "    df['p_rounds_won'] = df['p_rounds_won'] / 100\n",
    "\n",
    "    df['opening_duels'] = df['opening_duels'].replace(to_replace='\\%',value='',regex=True)\n",
    "    df['opening_duels'] = pd.to_numeric(df['opening_duels'])\n",
    "    df['opening_duels'] = df['opening_duels'] / 100\n",
    "\n",
    "    df['team_5v4'] = df['team_5v4'].replace(to_replace='\\%',value='',regex=True)\n",
    "    df['team_5v4'] = pd.to_numeric(df['team_5v4'])\n",
    "    df['team_5v4'] = df['team_5v4'] / 100\n",
    "\n",
    "    df['team_4v5'] = df['team_4v5'].replace(to_replace='\\%',value='',regex=True)\n",
    "    df['team_4v5'] = pd.to_numeric(df['team_4v5'])\n",
    "    df['team_4v5'] = df['team_4v5'] / 100\n",
    "\n",
    "    df['team_traded'] = df['team_traded'].replace(to_replace='\\-',value='',regex=True)\n",
    "    df['team_traded'] = df['team_traded'].replace(to_replace='\\%',value='',regex=True)\n",
    "    df['team_traded'] = pd.to_numeric(df['team_traded'])\n",
    "    df['team_traded'] = df['team_traded'] / 100\n",
    "    df['utility_adr'] = df['utility_adr'].replace(to_replace='\\-',value='',regex=True)\n",
    "    df['utility_adr'] = pd.to_numeric(df['utility_adr'])\n",
    "\n",
    "\n",
    "    df['utility_flash'] = df['utility_flash'].replace(to_replace='\\-',value='',regex=True)\n",
    "    df['utility_flash'] = pd.to_numeric(df['utility_flash'])\n",
    "    \n",
    "    df['team_traded'] = df['team_traded'].fillna(df.groupby('team')['team_traded'].mean())\n",
    "    df['utility_adr'] = df['utility_adr'].fillna(df.groupby('team')['utility_adr'].mean())\n",
    "    df['utility_flash'] = df['utility_flash'].fillna(df.groupby('team')['utility_flash'].mean())\n",
    "    \n",
    "    df['team_traded'] = df['team_traded'].interpolate(method='linear',limit_direction='both')\n",
    "    df['utility_adr'] = df['utility_adr'].interpolate(method='linear',limit_direction='both')\n",
    "    df['utility_flash'] = df['utility_flash'].interpolate(method='linear',limit_direction='both')\n",
    "    \n",
    "    \n",
    "    df['opposing_team_rank'] = -1\n",
    "    df['team_rank'] = -1\n",
    "    for index, row in df.iterrows():\n",
    "        df.at[index, 'opposing_team_rank'] = get_rank(\n",
    "            row['opposing_team'], row['date'])\n",
    "        df.at[index, 'team_rank'] = get_rank(\n",
    "            row['team'], row['date'])\n",
    "\n",
    "    # stats for each player per game\n",
    "    if df['deaths'] != 0:\n",
    "        df['kdr'] = df['kills'] / df['deaths']\n",
    "    else:\n",
    "        df['kdr'] = df['kills'] / (df['deaths'] + 1)\n",
    "    df['kpr'] = df['kills'] / (df['team_rounds'] + df['opposing_team_rounds'])\n",
    "    \n",
    "    df['n_impact'] = 0.5*((df['avg_impact'])**2 - (df['avg_impact'].mean())**2)\n",
    "    df['performance'] = df['rating'] + df['n_impact']\n",
    "    \n",
    "    df['rank_differential'] = df.apply(lambda x: 31 if x['team_rank'] == -1 or x['opposing_team_rank'] == -1 else x['opposing_team_rank'] - x['team_rank'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    df['rank_weight'] = df.apply(rank_weight, axis=1)\n",
    "\n",
    "    # weighted performance\n",
    "    df['w_performance'] = df['performance'] * df['rank_weight']\n",
    "\n",
    "    # performance residual - accounted for impact and ranking of teams\n",
    "    df['perf_resid'] = df['w_performance'] - df['rating']\n",
    "    \n",
    "    df['perf_resid_lag'] = df.groupby('player')['perf_resid'].shift(1)\n",
    "\n",
    "    df['perf_resid_lag'] = df.groupby('player')['perf_resid_lag'].fillna(method='bfill')\n",
    "    \n",
    "    df.to_csv(data_filepath + 'final_df.csv', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    data['date'] = pd.to_datetime(data.date)\n",
    "    data = data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    data = data[data['team']!='Sprout']\n",
    "    \n",
    "    cd = data.groupby('team').mean()['kdr']\n",
    "    cd = cd.reset_index()\n",
    "    cd.columns = ['team','mean_team_kdr']\n",
    "    \n",
    "    data = data.merge(cd, on=['team'], how='left')\n",
    "    \n",
    "    td = data.groupby('team').mean()['kpr']\n",
    "    td = td.reset_index()\n",
    "    td.columns = ['team','mean_team_kpr']\n",
    "    \n",
    "    data = data.merge(td, on=['team'], how='left')\n",
    "    \n",
    "    rows = []\n",
    "    for index, row in data.iterrows():\n",
    "        feature_set = []\n",
    "        feature_set.append(row[\"team\"])\n",
    "        feature_set.append(row[\"kills\"])\n",
    "        feature_set.append(row[\"deaths\"])\n",
    "        feature_set.append(row[\"map\"])\n",
    "        feature_set.append(row[\"opposing_team\"])\n",
    "        feature_set.append(row[\"rating\"])\n",
    "        feature_set.append(row[\"avg_impact\"])\n",
    "        feature_set.append(row[\"p_rounds_won\"])\n",
    "        feature_set.append(row[\"opening_duels\"])\n",
    "        feature_set.append(row[\"multi_kills\"])\n",
    "        feature_set.append(row[\"team_5v4\"])\n",
    "        feature_set.append(row[\"team_4v5\"])\n",
    "        feature_set.append(row[\"team_traded\"])\n",
    "        feature_set.append(row[\"utility_adr\"])\n",
    "        feature_set.append(row[\"utility_flash\"])\n",
    "        feature_set.append(row[\"target\"])\n",
    "        feature_set.append(row[\"opposing_team_rank\"])\n",
    "        feature_set.append(row[\"team_rank\"])\n",
    "        feature_set.append(row[\"kdr\"])\n",
    "        feature_set.append(row[\"kpr\"])\n",
    "        feature_set.append(row[\"n_impact\"])\n",
    "        feature_set.append(row[\"performance\"])\n",
    "        feature_set.append(row[\"rank_differential\"])\n",
    "        feature_set.append(row[\"rank_weight\"])\n",
    "        feature_set.append(row[\"w_performance\"])\n",
    "        feature_set.append(row[\"perf_resid\"])\n",
    "        feature_set.append(row[\"perf_resid_lag\"])\n",
    "        feature_set.append(row[\"mean_team_kpr\"])\n",
    "        feature_set.append(row[\"mean_team_kdr\"])\n",
    "        rows.append(feature_set)\n",
    "        \n",
    "    mdf = pd.DataFrame(data=rows, columns=[\n",
    "         'team',\n",
    "         'kills',\n",
    "         'deaths',\n",
    "         'map',\n",
    "         'opposing_team',\n",
    "         'rating',\n",
    "         'avg_impact',\n",
    "         'p_rounds_won',\n",
    "         'opening_duels',\n",
    "         'multi_kills',\n",
    "         'team_5v4',\n",
    "         'team_4v5',\n",
    "         'team_traded',\n",
    "         'utility_adr',\n",
    "         'utility_flash',\n",
    "         'target',\n",
    "         'opposing_team_rank',\n",
    "         'team_rank',\n",
    "         'kdr',\n",
    "         'kpr',\n",
    "         'n_impact',\n",
    "         'performance',\n",
    "         'rank_differential',\n",
    "         'rank_weight',\n",
    "         'w_performance',\n",
    "         'perf_resid',\n",
    "         'perf_resid_lag',\n",
    "         'mean_team_kdr',\n",
    "         'mean_team_kpr'\n",
    "    ])   \n",
    "    \n",
    "    new_rows = []\n",
    "    for index, row in mdf.iterrows():\n",
    "        pset = []\n",
    "        pset.append(row[\"team\"])\n",
    "        pset.append(row[\"opposing_team\"])\n",
    "        pset.append(row[\"map\"])\n",
    "        pset.append(row[\"target\"])\n",
    "        pset.append([\n",
    "            row[\"kdr\"],\n",
    "            row[\"kpr\"],\n",
    "            row[\"opening_duels\"],\n",
    "            row[\"multi_kills\"],\n",
    "            row[\"team_5v4\"],\n",
    "            row[\"team_4v5\"],\n",
    "            row[\"team_traded\"],\n",
    "            row[\"utility_adr\"],\n",
    "            row[\"utility_flash\"],\n",
    "            row[\"performance\"],\n",
    "            row[\"rank_differential\"],\n",
    "            row[\"perf_resid\"],\n",
    "            row[\"mean_team_kpr\"],\n",
    "            row[\"mean_team_kdr\"]\n",
    "        ])\n",
    "        new_rows.append(pset)\n",
    "    \n",
    "    df = pd.DataFrame(data=new_rows, columns=[\"team\", \"opponent\", \"map\", \"target\", \"X\"])\n",
    "        \n",
    "    df = df.sample(frac=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(listOfLists):\n",
    "    \"Flatten one level of nesting\"\n",
    "    return chain.from_iterable(listOfLists)\n",
    "\n",
    "def get_model(model, df, train_size):\n",
    "    X = pd.DataFrame(df['X'].tolist())\n",
    "    y = df['target']\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,y,train_size=train_size,random_state=123)\n",
    "    \n",
    "    # specify model in final\n",
    "    model.fit(x_train,y_train)\n",
    "    train_score = cross_val_score(model,x_train,y_train,cv=10)\n",
    "    print(f'Train Score:\\t{train_score.mean()}\\nTScore STD:\\t {train_score.std()}')\n",
    "    return model, x_train, x_test, y_train, y_test\n",
    "\n",
    "def eval_model(model,x_test,y_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    cr = metrics.classification_report(y_test,y_pred)\n",
    "    print(\"Accuracy: %f\" % (acc))\n",
    "    print(f\"Classification Report:\\n{cr}\")\n",
    "    return y_pred, acc, cr\n",
    "\n",
    "def pickle_model():\n",
    "    model,_ = final_model()\n",
    "    _,acc,_ = eval_model(model, x_test, y_test)\n",
    "    \n",
    "    filepath = 'C:/Users/Tim/Desktop/lighthouse/w11,12 - final project/'\n",
    "    model_filepath = filepath+'model.pickle'\n",
    "    \n",
    "    if not os.path.exists(model_filepath):\n",
    "        model.to_pickle(model_filepath)\n",
    "    else:\n",
    "        old_model = pickle.load(model_filepath)\n",
    "        _,old_acc,_ = eval_model(old_model,x_test,y_test)\n",
    "        if acc > old_acc:\n",
    "            model.to_pickle(model_filepath)\n",
    "        else:\n",
    "            print('Accuracy not better than old model, use old model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_deploy():\n",
    "    \n",
    "    # get data\n",
    "    # data = prep_scraped_data()\n",
    "    filepath='C:/Users/Tim/Desktop/lighthouse/w11,12 - final project/'\n",
    "    data_filepath = filepath+'data/'\n",
    "    file_name = 'final_df.csv'\n",
    "    data = get_data(data_filepath, file_name)\n",
    "    \n",
    "    # prep data\n",
    "    df = clean_data(data)\n",
    "    \n",
    "    # model\n",
    "    model = XGBClassifier(# objective ='reg:squaredlogerror',\n",
    "                     # objective = 'reg:logistic',\n",
    "                     objective = 'binary:logistic',\n",
    "                     eval_metric = 'logloss',\n",
    "                     use_label_encoder=False,\n",
    "                     booster='gbtree',\n",
    "                     learning_rate = 0.3,\n",
    "                     colsample_bytree = 1,\n",
    "                     max_depth = 10, \n",
    "                     alpha = 0,\n",
    "                     n_estimators = 100)\n",
    "    \n",
    "    model_, x_train, x_test, y_train, y_test = get_model(model, df, train_size = 0.7)\n",
    "    \n",
    "    # eval model\n",
    "    eval_model(model_,x_test,y_test)\n",
    "    \n",
    "    # don't use this if model from xgboost\n",
    "    # pickle_model()\n",
    "    \n",
    "    return model_, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [0.515000, 0.870000, 0.757000, 0.313000, 0.206000, 18.500000, 0.230000, 1.261408, 3, 1.261408, 0.071408, 1.136444, 0.689899]\n",
    "\n",
    "def get_prediction(team, map_, opposing_team, sample, df):\n",
    "    \n",
    "# sample has to be a *list* of these variables in this order\n",
    "#             [\"kdr\"],\n",
    "#             [\"kpr\"],\n",
    "#             [\"opening_duels\"],\n",
    "#             [\"multi_kills\"],\n",
    "#             [\"team_5v4\"],\n",
    "#             [\"team_4v5\"],\n",
    "#             [\"team_traded\"],\n",
    "#             [\"utility_adr\"],\n",
    "#             [\"utility_flash\"],\n",
    "#             [\"performance\"],\n",
    "#             [\"rank_differential\"],\n",
    "#             [\"perf_resid\"],\n",
    "#             [\"mean_team_kpr\"],\n",
    "#             [\"mean_team_kdr\"]\n",
    "\n",
    "    model,_ = final_deploy()\n",
    "#     model = pickle.load(model_filepath)\n",
    "    \n",
    "    ourSet = sample    \n",
    "    t = df.loc[df['team'] == team]\n",
    "    t = t.loc[df['map'] == map_] \n",
    "    t = t.loc[df['opponent'] == opposing_team]\n",
    "    m = np.array(t['X'].tolist()).mean(axis=0)\n",
    "   \n",
    "    # X = list(np.subtract(ourSet, m))\n",
    "    X = np.subtract(ourSet, m).reshape(1,-1)\n",
    "    \n",
    "    print(f'{team} vs {opposing_team} on {map_} prediction:')\n",
    "    # X[0] = probability of class 0 (loss), X[1] = probability of class 1\n",
    "    return model.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [0.515000, 0.870000, 0.757000, 0.313000, 0.206000, 18.500000, 0.230000, 1.261408, 3, 1.261408, 0.071408, 1.136444, 0.689899, 2, 3]\n",
    "\n",
    "get_prediction(\"Liquid\", \"inf\", \"Astralis\", sample, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,_ = final_deploy()\n",
    "\n",
    "sample_array = np.array(sample).reshape(1,-1)\n",
    "\n",
    "model.predict_proba(sample_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
