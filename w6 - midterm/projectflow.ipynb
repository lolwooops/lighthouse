{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the packages here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# import Kmeans \n",
    "from sklearn.cluster import KMeans\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Download your data and load them into the Python.\n",
    "You can find them [**here**](https://drive.google.com/file/d/0Bz9_0VdXvv9bX0MzUEhVdmpCc3c/view?usp=sharing).\n",
    "\n",
    "- Features and response variables are in different files\n",
    "- be careful about number of spaces between the values in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.read_csv('features.txt',sep='\\s+',header=None)\n",
    "names=names.drop([0],axis=1)\n",
    "names = np.asarray(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(tBodyAcc-mean()-X,)</th>\n",
       "      <th>(tBodyAcc-mean()-Y,)</th>\n",
       "      <th>(tBodyAcc-mean()-Z,)</th>\n",
       "      <th>(tBodyAcc-std()-X,)</th>\n",
       "      <th>(tBodyAcc-std()-Y,)</th>\n",
       "      <th>(tBodyAcc-std()-Z,)</th>\n",
       "      <th>(tBodyAcc-mad()-X,)</th>\n",
       "      <th>(tBodyAcc-mad()-Y,)</th>\n",
       "      <th>(tBodyAcc-mad()-Z,)</th>\n",
       "      <th>(tBodyAcc-max()-X,)</th>\n",
       "      <th>...</th>\n",
       "      <th>(fBodyBodyGyroJerkMag-meanFreq(),)</th>\n",
       "      <th>(fBodyBodyGyroJerkMag-skewness(),)</th>\n",
       "      <th>(fBodyBodyGyroJerkMag-kurtosis(),)</th>\n",
       "      <th>(angle(tBodyAccMean,gravity),)</th>\n",
       "      <th>(angle(tBodyAccJerkMean),gravityMean),)</th>\n",
       "      <th>(angle(tBodyGyroMean,gravityMean),)</th>\n",
       "      <th>(angle(tBodyGyroJerkMean,gravityMean),)</th>\n",
       "      <th>(angle(X,gravityMean),)</th>\n",
       "      <th>(angle(Y,gravityMean),)</th>\n",
       "      <th>(angle(Z,gravityMean),)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074323</td>\n",
       "      <td>-0.298676</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158075</td>\n",
       "      <td>-0.595051</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414503</td>\n",
       "      <td>-0.390748</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404573</td>\n",
       "      <td>-0.117290</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087753</td>\n",
       "      <td>-0.351471</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (tBodyAcc-mean()-X,)  (tBodyAcc-mean()-Y,)  (tBodyAcc-mean()-Z,)  \\\n",
       "0              0.288585             -0.020294             -0.132905   \n",
       "1              0.278419             -0.016411             -0.123520   \n",
       "2              0.279653             -0.019467             -0.113462   \n",
       "3              0.279174             -0.026201             -0.123283   \n",
       "4              0.276629             -0.016570             -0.115362   \n",
       "\n",
       "   (tBodyAcc-std()-X,)  (tBodyAcc-std()-Y,)  (tBodyAcc-std()-Z,)  \\\n",
       "0            -0.995279            -0.983111            -0.913526   \n",
       "1            -0.998245            -0.975300            -0.960322   \n",
       "2            -0.995380            -0.967187            -0.978944   \n",
       "3            -0.996091            -0.983403            -0.990675   \n",
       "4            -0.998139            -0.980817            -0.990482   \n",
       "\n",
       "   (tBodyAcc-mad()-X,)  (tBodyAcc-mad()-Y,)  (tBodyAcc-mad()-Z,)  \\\n",
       "0            -0.995112            -0.983185            -0.923527   \n",
       "1            -0.998807            -0.974914            -0.957686   \n",
       "2            -0.996520            -0.963668            -0.977469   \n",
       "3            -0.997099            -0.982750            -0.989302   \n",
       "4            -0.998321            -0.979672            -0.990441   \n",
       "\n",
       "   (tBodyAcc-max()-X,)  ...  (fBodyBodyGyroJerkMag-meanFreq(),)  \\\n",
       "0            -0.934724  ...                           -0.074323   \n",
       "1            -0.943068  ...                            0.158075   \n",
       "2            -0.938692  ...                            0.414503   \n",
       "3            -0.938692  ...                            0.404573   \n",
       "4            -0.942469  ...                            0.087753   \n",
       "\n",
       "   (fBodyBodyGyroJerkMag-skewness(),)  (fBodyBodyGyroJerkMag-kurtosis(),)  \\\n",
       "0                           -0.298676                           -0.710304   \n",
       "1                           -0.595051                           -0.861499   \n",
       "2                           -0.390748                           -0.760104   \n",
       "3                           -0.117290                           -0.482845   \n",
       "4                           -0.351471                           -0.699205   \n",
       "\n",
       "   (angle(tBodyAccMean,gravity),)  (angle(tBodyAccJerkMean),gravityMean),)  \\\n",
       "0                       -0.112754                                 0.030400   \n",
       "1                        0.053477                                -0.007435   \n",
       "2                       -0.118559                                 0.177899   \n",
       "3                       -0.036788                                -0.012892   \n",
       "4                        0.123320                                 0.122542   \n",
       "\n",
       "   (angle(tBodyGyroMean,gravityMean),)  \\\n",
       "0                            -0.464761   \n",
       "1                            -0.732626   \n",
       "2                             0.100699   \n",
       "3                             0.640011   \n",
       "4                             0.693578   \n",
       "\n",
       "   (angle(tBodyGyroJerkMean,gravityMean),)  (angle(X,gravityMean),)  \\\n",
       "0                                -0.018446                -0.841247   \n",
       "1                                 0.703511                -0.844788   \n",
       "2                                 0.808529                -0.848933   \n",
       "3                                -0.485366                -0.848649   \n",
       "4                                -0.615971                -0.847865   \n",
       "\n",
       "   (angle(Y,gravityMean),)  (angle(Z,gravityMean),)  \n",
       "0                 0.179941                -0.058627  \n",
       "1                 0.180289                -0.054317  \n",
       "2                 0.180637                -0.049118  \n",
       "3                 0.181935                -0.047663  \n",
       "4                 0.185151                -0.043892  \n",
       "\n",
       "[5 rows x 561 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Features\n",
    "X = pd.read_table('X_train.txt',sep='\\s+',header=None)\n",
    "X.columns = names\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().values.any() # eliminate any column that has more than 40% missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correllation with cutoff of < 80%\n",
    "# remove what you can\n",
    "# list with correlation value\n",
    "# eric lecture included code?\n",
    "from scipy.signal import correlate\n",
    "corr_matrix = X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-25bc3fc4b21d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcorr_matrix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "for i in corr_matrix:\n",
    "    for j in range(i):\n",
    "        if abs.corr_matrix[i][j] > 0.8:\n",
    "            print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out eigen values to choose n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling not necessary right now\n",
    "# PCA - combines variables together; dimension reduction technique \n",
    "# clustering is about finding groups (e.g. KMeans,DBSCAN), commonality between columns you have - no combination\n",
    "# if more than 50/60 columns, then reduce variables \n",
    "# keep into account eigenvalues > 1 (# of components PC1,PC2,...PCi)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check variance explained with corr and without corr to examine difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Response, dependent variable\n",
    "y = pd.read_table('y_train.txt',header=None)\n",
    "#change column name activity_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data to create predictions should be separated ahead of this\n",
    "# create train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of accuracies and parameter values (eg in Excel) as a log\n",
    "# can save models as check points or pickles or hyp5 (e.g run in google collab and then bring into your own notebook)\n",
    "# dataset that you train model on must be the same shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use logistic regression, NB, random forest - compare all\n",
    "# check accuracies (set reference point)\n",
    "# do not include things like hyperparameter tuning - just defaults \n",
    "# do this all with PCA and then compare without PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceed with algorithm with highest accuracy and go forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once you decide on model you start data pre-processing - \n",
    "# check for imbalance in data (bootstrap, SMOTe)\n",
    "# create approach tree; create multiple dataframes/models - scaling, label encoding, hot-encoding, etc\n",
    "# ensure that train test split same for all dataframes (note that model doesnt have memory of previous runs)\n",
    "# compare different libraries, different methods (try scaling, dummies, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start permutation combinations (eg scaling + hot-encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking only for best training accuracy right now - get as high as possible\n",
    "# use cross validation (k_value never greater than 25; try multiples of 5)\n",
    "# e.g. logistic regression - checking information value; classify variables where importance is higher\n",
    "# e.g. age variable - keep as numeric, next try as bins (note bins is always better)\n",
    "# if scaling doesn't improve, then try log normalization \n",
    "# p-values (eg. .summary()), mcfadden values\n",
    "# run the same code again and again with train test split (of full dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you have high accuracy, declare final model\n",
    "# want to obtain a model that is accurate (training) and robust (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start to run test data to create predicitions; check predictions \n",
    "# 3 types of errors\n",
    "# 1) overfit - check feature engineering (# of columns) (do or don't do)\n",
    "# 2) optimization - not optimized accurately; train model better\n",
    "# 3) approximation - algorithim could be wrong, even if given good accuracy; go back and try 2nd highest accuracy model\n",
    "# re run everything with 2nd highest accuracy model to check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Create Binary target variable: categories 1,2,3 --> 1, categories 4,5,6 --> 0 \n",
    "This will represent binary variable indicating if person is walking or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "+ Create Univariate Binary Logistic Regression with feature number 54, which represents `tGravityAcc-min()-Y`: gravity acceleration signals in direction of Y\n",
    "+ Compare the results of Logistic regressions from different Python packages (sklearn, statsmodel)\n",
    "+ Plot the FIT of predicted probabilities to the original values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "- Try to fit Binary Logistic Regression with all the features? How many are significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "Now, let's fit Multinomial Logistic regression to predict all categories. Firstly, we can start with **Univariate** model for these features number separately:\n",
    "+ 4\n",
    "+ 54\n",
    "- 19\n",
    "\n",
    "Check the contingency matrix to see the effect of particular features!! (each feature can be good in predicting different categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "Fit the Multinomial Logistic Regression model again. Now, try to choose **all** important features we have in the dataset. Who will get the best predictions with the smallest number of features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 (Stretch)\n",
    "Create your own function for Stepwise selection. Use either sklearn or statsmodel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
