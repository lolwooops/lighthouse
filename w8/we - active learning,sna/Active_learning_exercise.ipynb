{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the titanic dataset here: https://drive.google.com/file/d/0Bz9_0VdXvv9bbVhpOEMwUDJ2elU/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will simulate active learning. We will keep the small sample of observations for testing and we will test how quality of the model rises when we use active learning to choose labeled observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data into variable df\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from operator import itemgetter \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/Tim/Desktop/lighthouse/w8/we/'\n",
    "file = 'titanic.csv'\n",
    "df = pd.read_csv(filepath+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SAMPLE\n",
    "# USE THIS SAMPLE ONLY FOR TESTING\n",
    "test_df = df.sample(n=100, random_state=42)\n",
    "# KEEP ONLY THOSE WHO ARE NOT IN THE TEST SET\n",
    "df = df[~df.PassengerId.isin(test_df.PassengerId.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIT THE FIRST MODEL ONLY ON THE DATAFRAME START_DF\n",
    "start_df = df.sample(n=100, random_state=42)\n",
    "# DROP OBS FROM START_DF FROM DF\n",
    "df = df[~df.PassengerId.isin(start_df.PassengerId.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_start = start_df.drop(columns='survived')\n",
    "# y_start = start_df['survived']\n",
    "# X_test = test_df.drop(columns='survived')\n",
    "# y_test = test_df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = copy.deepcopy(start_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(data):\n",
    "    new_data = copy.deepcopy(data)\n",
    "    new_data.drop(['PassengerId','Name','Ticket','Cabin'], axis =1, inplace = True)\n",
    "    new_data['Age'].fillna(np.mean(new_data['Age']), inplace = True)\n",
    "    new_data['Age'].fillna(new_data['Embarked'].mode()[0], inplace = True)\n",
    "    le = LabelEncoder()\n",
    "    new_data['Sex'] = le.fit_transform(new_data['Sex'])\n",
    "    new_data['Embarked'] = le.fit_transform(new_data['Embarked'].astype(str))\n",
    "    num_feats = new_data[['Age','Fare']]\n",
    "    scaled = StandardScaler().fit_transform(num_feats)\n",
    "    new_data['Age'] = scaled[:,0]\n",
    "    new_data['Fare'] = scaled[:,1]\n",
    "    return(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_data.drop('Survived', axis = 1)\n",
    "y = clean_data['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. fit the first model only on the **start_df** using **SVM** and evaluate accuracy, precision and recall on test_df\n",
    "2. in each iteration, add 10 observations from **df** to your trainset (choose the observation using active learning approach) \n",
    "    - score all observations in df and take 10 where the model isn't sure what class it is. The probability of surviving will be around 50% \n",
    "3. refit the model and evaluate on **test_df** again.    \n",
    "3. the goal is to converge to the optimal solution as fast as possible by choosing **right** observations in each iteration\n",
    "4. plot the graphs for each eval metric, where on the axis x is iteration number, on y is the metric value for that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train,x_test,y_train,y_test = train_test_split(X,y,train_size=0.7,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model(model,X_train,y_train,X_test,y_test):\n",
    "#     model = model\n",
    "#     model.fit(X_train,y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     print(metrics.accuracy(y_pred,y_test))\n",
    "#     print(metrics.classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(probability = True)\n",
    "svc.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict((clean(test_df).drop(['Survived'],axis = 1)))\n",
    "y_proba = svc.predict_proba((clean(test_df).drop(['Survived'],axis = 1)))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(y_proba[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(test_df['Survived'],y_pred))\n",
    "print(recall_score(test_df['Survived'],y_pred))\n",
    "print(precision_score(test_df['Survived'],y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filepath+file, header = 0)\n",
    "df = copy.deepcopy(data)\n",
    "test_df = df.sample(n=100, random_state=42)\n",
    "df = df[~df.PassengerId.isin(test_df.PassengerId.tolist())]\n",
    "start_df = df.sample(n=100, random_state=42)\n",
    "df = df[~df.PassengerId.isin(start_df.PassengerId.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = copy.deepcopy(start_df)\n",
    "clean_data = clean(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "batch = 10\n",
    "metrics = []\n",
    "svc = SVC(probability = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(iterations):\n",
    "    X = clean_data.drop('Survived', axis = 1)\n",
    "    y = clean_data['Survived']\n",
    "    svc.fit(X,y)\n",
    "    y_pred = svc.predict((clean(test_df).drop(['Survived'],axis = 1)))\n",
    "    acc = accuracy_score(test_df['Survived'],y_pred)\n",
    "    recall = recall_score(test_df['Survived'],y_pred)\n",
    "    precision = precision_score(test_df['Survived'],y_pred)\n",
    "    met = [acc,recall,precision]\n",
    "    metrics.append(met)\n",
    "    \n",
    "    temp_preds = svc.predict_proba((clean(df).drop(['Survived'],axis = 1)))\n",
    "    margin_sample = abs(temp_preds[:,0] - temp_preds[:,1])\n",
    "    to_get = list(itemgetter(*list(margin_sample.argsort()[:batch]))(df.index.values.tolist()))\n",
    "    #to_get = list(np.argpartition(margin_sample, 5)[:5])\n",
    "    #print(to_get)\n",
    "    clean_data = pd.concat([clean_data,clean(df.loc[to_get,:])])\n",
    "    \n",
    "    df.drop(to_get, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(metrics)\n",
    "temp = temp.rename(columns={0: 'accuracy',1:'recall',2:'precision'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "temp.accuracy.plot(legend=True)\n",
    "temp.recall.plot(legend=True) \n",
    "temp.precision.plot(legend=True)\n",
    "plt.xlabel('iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
