{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this challenge, we will work with the same [dataset](https://drive.google.com/file/d/1B07fvYosBNdIwlZxSmxDfeAf9KaygX89/view?usp=sharing) as during previous weeks, **Prediction of Sales**. The main goal is to create **pipeline** that covers all data preprocessing and modeling steps.\n",
    "\n",
    "\n",
    "**TASK 1**: Build Pipeline which will end with regression model to predict `Item_Outlet_Sales` from the dataset. The pipeline should have following steps:\n",
    "\n",
    "- split features to numerical and categorical (text)\n",
    "- null value replacement\n",
    "    - mean for numerical variables\n",
    "    - the most frequent value for categorical\n",
    "- creating dummy variables from categorical features\n",
    "- Use PCA to reduce number of dummy variables to 3 principal components. PCA will be used directly after OneHotEncoder that outputs data in the SparseMatrix so we need to use **ToDenseTransformer** from the [article about custom pipelines](https://queirozf.com/entries/scikit-learn-pipelines-custom-pipelines-and-pandas-integration).\n",
    "- select 3 best candidates from original numeric features using KBest\n",
    "- Fit Ridge regression (default alpha is fine for now)\n",
    "\n",
    "**TASK 2**: Tune parameters of models as well as preprocessing steps and find the best solution\n",
    "- Try models: Random Forest, Gradient Boosting Regressor or Ridge Regression. We need to use the approach from the [earlier article](https://iaml.it/blog/optimizing-sklearn-pipelines), in the section **PIPELINE TUNING (ADVANCED VERSION)**, when we tried different scalers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filepath = 'C:/Users/Tim/Desktop/lighthouse/w7/d1/'\n",
    "df = pd.read_csv(filepath+\"regression_exercise.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating target variable\n",
    "# y = df[\"Item_Outlet_Sales\"]\n",
    "# df = df.drop([\"Item_Outlet_Sales\",\"Item_Identifier\"],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting to train and test set in the begining. We should always do this before Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df.sample(frac=0.8).sort_index()\n",
    "# y_train = y[y.index.isin(df_train.index.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = df[~df.index.isin(df_train.index.tolist())].sort_index()\n",
    "# y_test = y[y.index.isin(df_test.index.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_missing</th>\n",
       "      <th>percent_missing</th>\n",
       "      <th>type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Outlet_Size</th>\n",
       "      <td>2410</td>\n",
       "      <td>0.282764</td>\n",
       "      <td>object</td>\n",
       "      <td>6113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Weight</th>\n",
       "      <td>1463</td>\n",
       "      <td>0.171653</td>\n",
       "      <td>float64</td>\n",
       "      <td>7060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>float64</td>\n",
       "      <td>8523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>object</td>\n",
       "      <td>8523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>object</td>\n",
       "      <td>8523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>int64</td>\n",
       "      <td>8523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>object</td>\n",
       "      <td>8523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_MRP</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>float64</td>\n",
       "      <td>8523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>object</td>\n",
       "      <td>8523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Visibility</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>float64</td>\n",
       "      <td>8523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>object</td>\n",
       "      <td>8523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Identifier</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>object</td>\n",
       "      <td>8523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           number_missing  percent_missing     type  count\n",
       "Outlet_Size                          2410         0.282764   object   6113\n",
       "Item_Weight                          1463         0.171653  float64   7060\n",
       "Item_Outlet_Sales                       0         0.000000  float64   8523\n",
       "Outlet_Type                             0         0.000000   object   8523\n",
       "Outlet_Location_Type                    0         0.000000   object   8523\n",
       "Outlet_Establishment_Year               0         0.000000    int64   8523\n",
       "Outlet_Identifier                       0         0.000000   object   8523\n",
       "Item_MRP                                0         0.000000  float64   8523\n",
       "Item_Type                               0         0.000000   object   8523\n",
       "Item_Visibility                         0         0.000000  float64   8523\n",
       "Item_Fat_Content                        0         0.000000   object   8523\n",
       "Item_Identifier                         0         0.000000   object   8523"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def info(x):\n",
    "    n_missing = x.isnull().sum().sort_values(ascending=False)\n",
    "    p_missing = (x.isnull().sum()/x.isnull().count()).sort_values(ascending=False)\n",
    "    dtype = x.dtypes\n",
    "    count = x.count()\n",
    "    missing_ = pd.concat([n_missing, p_missing, dtype, count],axis=1, keys = [\n",
    "        'number_missing',\n",
    "        'percent_missing',\n",
    "        'type',\n",
    "        'count'\n",
    "    ])\n",
    "    return missing_\n",
    "info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import TransformerMixin\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Item_Outlet_Sales','Item_Identifier'])\n",
    "y = df['Item_Outlet_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = list(X.dtypes[X.dtypes != 'object'].index)\n",
    "# num_train = x_train[numerical]\n",
    "# num_test = x_test[numerical]\n",
    "\n",
    "categorical = list(X.dtypes[X.dtypes == 'object'].index)\n",
    "# cat_train = x_train[categorical]\n",
    "# cat_test = x_test[categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Item_Fat_Content',\n",
       " 'Item_Type',\n",
       " 'Outlet_Identifier',\n",
       " 'Outlet_Size',\n",
       " 'Outlet_Location_Type',\n",
       " 'Outlet_Type']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='median'),\n",
    "    StandardScaler(),\n",
    "    SelectKBest(k=3)\n",
    ")\n",
    "# x_train[numerical] = num_pipe.fit_transform(x_train[numerical])\n",
    "# x_test[numerical] = num_pipe.fit_transform(x_test[numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('simpleimputer', SimpleImputer(strategy='median')),\n",
       " ('standardscaler', StandardScaler()),\n",
       " ('selectkbest', SelectKBest(k=3))]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy = 'constant', fill_value = 'unknown'),\n",
    "    OneHotEncoder(),\n",
    "    ToDenseTransformer(),\n",
    "    PCA(n_components=3)\n",
    ")\n",
    "# x_train[categorical] = cat_pipe.fit_transform(cat_train,columns=categorical)\n",
    "# x_test[categorical] = cat_pipe.fit_transform(cat_test,columns=categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('simpleimputer', SimpleImputer(fill_value='unknown', strategy='constant')),\n",
       " ('onehotencoder', OneHotEncoder()),\n",
       " ('todensetransformer', <__main__.ToDenseTransformer at 0x1a1b004ef10>),\n",
       " ('pca', PCA(n_components=3))]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('continuous', num_pipe, numerical),\n",
    "        ('categorical', cat_pipe, categorical),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe = Pipeline(steps = [\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', Ridge())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.3406801610232326\n"
     ]
    }
   ],
   "source": [
    "model_pipe.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model_pipe.predict(x_test)\n",
    "acc = metrics.r2_score(y_test, y_pred)\n",
    "print(f'Test set accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   52.7s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best test set accuracy: 0.5418883744291152\n",
      "Achieved with hyperparameters: {'clf__alpha': 1, 'preprocess__categorical__pca__n_components': 13, 'preprocess__continuous__selectkbest__k': 1}\n"
     ]
    }
   ],
   "source": [
    "# pipeline = Pipeline(steps=[('scaling', StandardScaler()),\n",
    "#                            ('features', feature_union),\n",
    "#                            ('classifier', RidgeClassifier())])\n",
    "\n",
    "# Find the best hyperparameters using GridSearchCV on the train set\n",
    "param_grid = {'clf__alpha': [0.001, 0.01, 0.1, 1], \n",
    "              'preprocess__categorical__pca__n_components': [1, 3, 5, 7, 9, 11, 13, 15, 17, 20],\n",
    "              'preprocess__continuous__selectkbest__k': [1, 2, 3, 4]}\n",
    "grid = GridSearchCV(model_pipe, param_grid=param_grid, cv=5,n_jobs=-1,verbose=1)\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "best_hyperparams = grid.best_params_\n",
    "best_acc = grid.score(x_test, y_test)\n",
    "print(f'Best test set accuracy: {best_acc}\\nAchieved with hyperparameters: {best_hyperparams}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task I\n",
    "\n",
    "### Split Features to numerical and categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_feats = df.dtypes[df.dtypes == 'object'].index.tolist()\n",
    "# num_feats = df.dtypes[~df.dtypes.index.isin(cat_feats)].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical = list(df.dtypes[df.dtypes != 'object'].index)\n",
    "# num_dat = df[numerical]\n",
    "\n",
    "# categorical = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "# cat_dat = df[categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# # Using own function in Pipeline\n",
    "# def numFeat(data):\n",
    "#     return data[num_feats]\n",
    "\n",
    "# def catFeat(data):\n",
    "#     return data[cat_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we will start two separate pipelines for each type of features\n",
    "# keep_num = FunctionTransformer(numFeat)\n",
    "# keep_cat = FunctionTransformer(catFeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.300</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>1999</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.920</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>2009</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.500</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>1999</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>1998</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>1987</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518</th>\n",
       "      <td>6.865</td>\n",
       "      <td>0.056783</td>\n",
       "      <td>214.5218</td>\n",
       "      <td>1987</td>\n",
       "      <td>2778.3834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8519</th>\n",
       "      <td>8.380</td>\n",
       "      <td>0.046982</td>\n",
       "      <td>108.1570</td>\n",
       "      <td>2002</td>\n",
       "      <td>549.2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8520</th>\n",
       "      <td>10.600</td>\n",
       "      <td>0.035186</td>\n",
       "      <td>85.1224</td>\n",
       "      <td>2004</td>\n",
       "      <td>1193.1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8521</th>\n",
       "      <td>7.210</td>\n",
       "      <td>0.145221</td>\n",
       "      <td>103.1332</td>\n",
       "      <td>2009</td>\n",
       "      <td>1845.5976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8522</th>\n",
       "      <td>14.800</td>\n",
       "      <td>0.044878</td>\n",
       "      <td>75.4670</td>\n",
       "      <td>1997</td>\n",
       "      <td>765.6700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8523 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Item_Weight  Item_Visibility  Item_MRP  Outlet_Establishment_Year  \\\n",
       "0           9.300         0.016047  249.8092                       1999   \n",
       "1           5.920         0.019278   48.2692                       2009   \n",
       "2          17.500         0.016760  141.6180                       1999   \n",
       "3          19.200         0.000000  182.0950                       1998   \n",
       "4           8.930         0.000000   53.8614                       1987   \n",
       "...           ...              ...       ...                        ...   \n",
       "8518        6.865         0.056783  214.5218                       1987   \n",
       "8519        8.380         0.046982  108.1570                       2002   \n",
       "8520       10.600         0.035186   85.1224                       2004   \n",
       "8521        7.210         0.145221  103.1332                       2009   \n",
       "8522       14.800         0.044878   75.4670                       1997   \n",
       "\n",
       "      Item_Outlet_Sales  \n",
       "0             3735.1380  \n",
       "1              443.4228  \n",
       "2             2097.2700  \n",
       "3              732.3800  \n",
       "4              994.7052  \n",
       "...                 ...  \n",
       "8518          2778.3834  \n",
       "8519           549.2850  \n",
       "8520          1193.1136  \n",
       "8521          1845.5976  \n",
       "8522           765.6700  \n",
       "\n",
       "[8523 rows x 5 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = copy.deepcopy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### null value replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use SimpleImputer\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.3, 'Low Fat', 0.016047301, ..., 'Medium', 'Tier 1',\n",
       "        'Supermarket Type1'],\n",
       "       [5.92, 'Regular', 0.019278216, ..., 'Medium', 'Tier 3',\n",
       "        'Supermarket Type2'],\n",
       "       [17.5, 'Low Fat', 0.016760075, ..., 'Medium', 'Tier 1',\n",
       "        'Supermarket Type1'],\n",
       "       ...,\n",
       "       [10.6, 'Low Fat', 0.035186271, ..., 'Small', 'Tier 2',\n",
       "        'Supermarket Type1'],\n",
       "       [7.21, 'Regular', 0.145220646, ..., 'Medium', 'Tier 3',\n",
       "        'Supermarket Type2'],\n",
       "       [14.8, 'Low Fat', 0.04487828, ..., 'Small', 'Tier 1',\n",
       "        'Supermarket Type1']], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null_values = ColumnTransformer([\n",
    "#         ('impute_mean', SimpleImputer(strategy='mean'), ['Item_Weight'])\n",
    "#     ], remainder='passthrough')\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     ('null', null_values)\n",
    "# ])\n",
    "\n",
    "# pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_preprocessing = Pipeline([('ohe', OneHotEncoder())])\n",
    "# numerical_preprocessing = Pipeline([('imputation', SimpleImputer())])\n",
    "\n",
    "# #define which transformer applies to which columns\n",
    "# preprocess = ColumnTransformer([\n",
    "#     ('categorical_preprocessing', categorical_preprocessing, keep_cat),\n",
    "#     ('simpleimput2', numerical_preprocessing, ['Item_Weight']),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in cat_dat:\n",
    "#     categorical_preprocessing = Pipeline([('ohe', OneHotEncoder())])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA to reduce number of dummy variables to 3 principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # don't forget ToDenseTransformer after one hot encoder\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.base import TransformerMixin\n",
    "# from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToDenseTransformer():\n",
    "\n",
    "    # here you define the operation it should perform\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    # just return self\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "# need to make matrices dense because PCA does not work with sparse vectors.\n",
    "dense = Pipeline([\n",
    "    ('to_dense',ToDenseTransformer()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_transform = ColumnTransformer([\n",
    "#     ('dense', dense, cat_dat)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select 3 best numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import FeatureUnion\n",
    "# from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# feature_union = FeatureUnion([('pca', PCA(n_components=3)), \n",
    "#                               ('select_best', SelectKBest(k=6))])\n",
    "\n",
    "# # kbest_transform = ColumnTransformer([\n",
    "# #     ('kbest_transform',SelectKBest(k=3),num_dat)\n",
    "# # ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# # Use base_model in Task I\n",
    "# base_model = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "# from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline(steps=[#('preprocess', preprocess),\n",
    "#                            #('dense_transform', dense_transform),\n",
    "# #                           ('pca_transform', pca_transform),\n",
    "# #                           ('kbest_transform',kbest_transform),\n",
    "#                            ('scaling', StandardScaler()),\n",
    "#                            ('features', feature_union),\n",
    "#                            ('classifier', Ridge())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline(steps = [\n",
    "    \n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.score(df_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = [\n",
    "# # \n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score is:  0.6241741712069144\n"
     ]
    }
   ],
   "source": [
    "# print('Final score is: ', tuned_model.score(df_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
