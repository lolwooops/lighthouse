{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search - hyperparameter tuning\n",
    "\n",
    "\"\"\"\n",
    "Grid search is the process of performing hyperparameter tuning so as to determine the optimal values for a given model. This is important as the \n",
    "performance of the entire model is based on the specified hyperparameter values.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import datasets, svm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the digit data\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# View the features of the first observation\n",
    "digits.data[0:1]\n",
    "\n",
    "#The target data is a vector containing the image’s true digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset 1\n",
    "data1_features = digits.data[:1000]\n",
    "data1_target = digits.target[:1000]\n",
    "\n",
    "# Create dataset 2\n",
    "data2_features = digits.data[1000:]\n",
    "data2_target = digits.target[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Before looking for which combination of parameter values produces the most accurate model, we must specify the different candidate values we want to try. \n",
    "In the code below we have a number of candidate parameter values, including four different values for C (1, 10, 100, 1000), two values for gamma (0.001, 0.0001), and two \n",
    "kernels (linear, rbf). The grid search will try all combinations of parameter values and select the set of parameters which provides the most accurate model.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "parameter_candidates = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conduct Grid Search To Find Parameters Producing Highest Score\n",
    "Now we are ready to conduct the grid search using scikit-learn’s GridSearchCV which stands for grid search cross validation. By default, the GridSearchCV’s cross validation uses \n",
    "3-fold KFold or StratifiedKFold depending on the situation.\n",
    "\"\"\"\n",
    "\n",
    "# Create a classifier object with the classifier and parameter candidates\n",
    "clf = GridSearchCV(estimator=svm.SVC(), param_grid=parameter_candidates, n_jobs=-1)\n",
    "\n",
    "# Train the classifier on data1's feature and target data\n",
    "clf.fit(data1_features, data1_target)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the accuracy score\n",
    "print('Best score for data1:', clf.best_score_) \n",
    "\n",
    "# View the best parameters for the model found using grid search\n",
    "print('Best C:',clf.best_estimator_.C) \n",
    "print('Best Kernel:',clf.best_estimator_.kernel)\n",
    "print('Best Gamma:',clf.best_estimator_.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Remember the second dataset we created? Now we will use it to prove that those parameters are actually used by the model. First, we apply the classifier we just trained to the\n",
    "second dataset. Then we will train a new support vector classifier from scratch using the parameters found using the grid search. We should get the same results for both models.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Apply the classifier trained using data1 to data2, and view the accuracy score\n",
    "clf.score(data2_features, data2_target)  \n",
    "\n",
    "# Train a new classifier using the best parameters found by the grid search\n",
    "svm.SVC(C=10, kernel='rbf', gamma=0.001).fit(data1_features, data1_target).score(data2_features, data2_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
